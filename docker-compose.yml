services:
  # Zookeeper для Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: ads-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - ads-net

  # Kafka брокер
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: ads-kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # Kafka доступна только внутри docker-сети (ads-net)
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 8
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - ads-net

  # Postgres для доменной модели (tenants, campaigns, placements, etc.)
  postgres:
    image: postgres:16
    container_name: ads-postgres
    restart: always
    environment:
      POSTGRES_DB: ads_db
      POSTGRES_USER: ads_user
      POSTGRES_PASSWORD: ads_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - ads-net

  # ClickHouse для сырых событий и агрегатов
  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    container_name: ads-clickhouse
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    ports:
      - "9000:9000"   # native protocol
      - "8123:8123"   # HTTP
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      # init.sql с CREATE TABLE ... из DESIGN.md
      - ./infra/clickhouse/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - ads-net

  # Redis для dedup (event_id) и frequency capping
  redis:
    image: redis:7
    container_name: ads-redis
    restart: always
    ports:
      - "6379:6379"
    networks:
      - ads-net

  # Django backend (API: ingest, reporting, decisioning)
  backend:
    image: faske7/ads-platform:${IMAGE_TAG:-latest}
    container_name: ads-backend
    command: >
      sh -c "
        cd backend && python manage.py migrate &&
        gunicorn config.wsgi:application --bind 0.0.0.0:8000
      "
    environment:
      DJANGO_SETTINGS_MODULE: config.settings
      # Postgres
      DATABASE_URL: postgres://ads_user:ads_password@postgres:5432/ads_db
      # Kafka
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      # ClickHouse
      CLICKHOUSE_HOST: clickhouse
      CLICKHOUSE_PORT: 9000
      CLICKHOUSE_DB: default
      # Redis
      REDIS_URL: redis://redis:6379/0
      # Любые другие настройки (SECRET_KEY и т.д.)
      DJANGO_SECRET_KEY: "dev-secret-key-change-me"
      DJANGO_DEBUG: "1"
    depends_on:
      - postgres
      - kafka
      - clickhouse
      - redis
    ports:
      - "8001:8000"
    networks:
      - ads-net

  # Тот же код, но запускаем consumer/worker (Kafka → ClickHouse)
  backend_worker:
    image: faske7/ads-platform:${IMAGE_TAG:-latest}
    container_name: ads-backend-worker
    command: >
      sh -c "
        cd backend && python manage.py consume_events
      "
    environment:
      DJANGO_SETTINGS_MODULE: config.settings
      DATABASE_URL: postgres://ads_user:ads_password@postgres:5432/ads_db
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      CLICKHOUSE_HOST: clickhouse
      CLICKHOUSE_PORT: 9000
      CLICKHOUSE_DB: default
      REDIS_URL: redis://redis:6379/0
      DJANGO_SECRET_KEY: "dev-secret-key-change-me"
      DJANGO_DEBUG: "1"
    depends_on:
      - postgres
      - kafka
      - clickhouse
      - redis
    networks:
      - ads-net

networks:
  ads-net:
    driver: bridge

volumes:
  postgres_data:
  clickhouse_data: